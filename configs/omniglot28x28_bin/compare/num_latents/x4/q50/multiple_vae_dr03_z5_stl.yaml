seed_everything: 20220118
experiment_subdir_base: logs/omniglot_28x28_bin/compare/num_latents/x4/q50/multiple_vae_dr03_z5_stl
add_checkpoint_callback: True
data:
  setup_seed: 20220118
  dataset: omniglot_28x28_bin
  use_test_instead_val: False
  batch_size: 150
  missingness: quadrants
  img_dims: [ 28, 28 ]
  total_miss_train: 0.50
  total_miss_val: 0.50
  pre_imputation: 'oracle'
  pre_impute_val: false
  filter_fully_missing_train: true
  filter_fully_missing_val: true
  data_root: ./data
model:
  class_path: vgiwae.models.MultipleVAE_FID
  init_args:
    # FID eval params
    fid_eval_step_freq: 1800
    inception_model_type: VAE_encoder
    inception_model_path: ./logs/omniglot_28x28_bin/compare/vae_dr03_z5_stl_complete/seed_m20220118_d20220118/lightning_logs/version_1765509/checkpoints/last.ckpt
    reference_samples: [ dataset_train, dataset_val, dataset_test ]
    num_samples_per_batch: 2000

    generator_network:
      class_path: vgiwae.shared.vae_resnet.ResNetDecoder
      init_args:
        output_shape: [1, 28, 28]
        layers: [2, 2, 2, 2]
        layer_widths: [256, 128, 64, 64]
        layer_upscale: [7, null, null, null]
        upscale_factor: 7
        downscaled_resolution: [4,4]
        latent_dim: 200
        dropout_prob: 0.3
    generator_distribution: bern_m1_p1
    prior_distribution: std_normal
    var_latent_network:
      class_path: vgiwae.shared.vae_resnet.ResNetEncoder
      init_args:
        input_shape: [1, 28, 28]
        layers: [2, 2, 2, 2]
        layer_widths: [64, 128, 256, 512]
        latent_dim: 2005 # 200dim 5comps # Should be latent_dim * num_components * num_params_per_component_dim + num_components
        dropout_prob: 0.3
        expect_miss_mask_as_extra_chennel: True
    var_latent_distribution: stratified_mixture5_normal_with_eps
    encoder_use_mis_mask: True
    kl_analytic: False
    var_latent_STL: True
    num_latent_samples: 1 # per component
    lr_generator: 1e-4
    lr_latent: 1e-4
    amsgrad_generator: True
    amsgrad_latent: True
    use_lr_scheduler: True
    init_imputation_distribution: false
    num_imputations_train: 1
    num_imputations_val: 1
    imputation_init_train: empirical
    imputation_init_val: empirical
trainer:
  # logger: true
  # checkpoint_callback: null
  # enable_checkpointing: true
  # callbacks: null
  # default_root_dir: null
  gradient_clip_val: 5
  gradient_clip_algorithm: norm
  # process_position: 0
  # num_nodes: 1
  # num_processes: 1
  # devices: null
  # gpus: null
  # auto_select_gpus: false
  # tpu_cores: null
  # ipus: null
  # log_gpu_memory: null
  # progress_bar_refresh_rate: null
  # enable_progress_bar: true
  # overfit_batches: 0.0
  # track_grad_norm: -1
  # check_val_every_n_epoch: 1
  # fast_dev_run: false
  # accumulate_grad_batches: null
  max_epochs: 200
  # min_epochs: null
  # max_steps: -1
  # min_steps: null
  # max_time: null
  # limit_train_batches: 1.0
  # limit_val_batches: 1.0
  # limit_test_batches: 1.0
  # limit_predict_batches: 1.0
  # val_check_interval: 1.0
  # flush_logs_every_n_steps: null
  log_every_n_steps: 1
  # accelerator: null
  # strategy: null
  # sync_batchnorm: false
  # precision: 32
  # enable_model_summary: true
  # weights_summary: top
  # weights_save_path: null
  # num_sanity_val_steps: 2
  # resume_from_checkpoint: null
  # profiler: null
  # benchmark: false
  # deterministic: false
  # reload_dataloaders_every_n_epochs: 0
  # reload_dataloaders_every_epoch: false
  # auto_lr_find: false
  # replace_sampler_ddp: true
  # detect_anomaly: false
  # auto_scale_batch_size: false
  # prepare_data_per_node: null
  # plugins: null
  # amp_backend: native
  # amp_level: null
  # move_metrics_to_cpu: false
  # multiple_trainloader_mode: max_size_cycle
  # stochastic_weight_avg: false
  # terminate_on_nan: null
